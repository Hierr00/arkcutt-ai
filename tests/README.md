# üß™ Tests - Context Engineering System

Suite completa de tests para el sistema de Context Engineering con RAG y Tools.

---

## üì¶ Test Structure

```
tests/
‚îú‚îÄ‚îÄ setup.ts                          # Test configuration
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ embeddings.service.test.ts   # Embeddings generation tests
‚îÇ   ‚îî‚îÄ‚îÄ rag.service.test.ts          # RAG system tests
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îú‚îÄ‚îÄ material.tools.test.ts       # Material agent tools tests
‚îÇ   ‚îî‚îÄ‚îÄ providers.tools.test.ts      # Providers agent tools tests
‚îî‚îÄ‚îÄ integration/
    ‚îî‚îÄ‚îÄ context-engineering.test.ts  # End-to-end integration tests
```

---

## üöÄ Running Tests

### Prerequisites

1. Configure `.env.local` with required credentials:
```bash
OPENAI_API_KEY=sk-...
NEXT_PUBLIC_SUPABASE_URL=https://...
NEXT_PUBLIC_SUPABASE_ANON_KEY=eyJ...
SUPABASE_SERVICE_ROLE_KEY=eyJ...
```

2. Ensure knowledge base is seeded:
```bash
npm run seed-knowledge
```

### Run All Tests

```bash
npm test
```

### Run Tests with UI

```bash
npm run test:ui
```

### Run Tests with Coverage

```bash
npm run test:coverage
```

### Run Specific Test Files

```bash
# Embeddings service tests
npx vitest tests/services/embeddings.service.test.ts

# RAG service tests
npx vitest tests/services/rag.service.test.ts

# Material tools tests
npx vitest tests/tools/material.tools.test.ts

# Providers tools tests
npx vitest tests/tools/providers.tools.test.ts

# Integration tests
npx vitest tests/integration/context-engineering.test.ts
```

### Watch Mode (for development)

```bash
npm test -- --watch
```

---

## üìä Test Coverage

### Embeddings Service
- ‚úÖ Generate embedding for text
- ‚úÖ Different embeddings for different texts
- ‚úÖ Caching mechanism
- ‚úÖ Long text handling
- ‚úÖ Batch processing

### RAG Service
- ‚úÖ Semantic search by query
- ‚úÖ Filter by agent type
- ‚úÖ Filter by category
- ‚úÖ Respect match threshold
- ‚úÖ Generate optimized RAG context
- ‚úÖ Respect max_tokens limit
- ‚úÖ Knowledge base statistics
- ‚úÖ Performance benchmarks

### Material Tools
- ‚úÖ Check material stock
- ‚úÖ Get material properties
- ‚úÖ Find material supplier
- ‚úÖ Suggest alternatives
- ‚úÖ Integration workflows

### Providers Tools
- ‚úÖ Search providers by service
- ‚úÖ Get provider information
- ‚úÖ Generate provider email
- ‚úÖ Generate material supplier email
- ‚úÖ Check if service is external (critical!)
- ‚úÖ Integration workflows

### Integration Tests
- ‚úÖ RAG context generation
- ‚úÖ Material agent with RAG
- ‚úÖ Proveedores agent with RAG
- ‚úÖ Ingenier√≠a agent with RAG
- ‚úÖ End-to-end workflows
- ‚úÖ Performance & token optimization
- ‚úÖ Quality assurance

---

## üéØ Key Test Scenarios

### 1. Token Optimization
```typescript
// Verifica que RAG reduce tokens en ~95%
it('should generate optimized context vs full database', async () => {
  const ragContext = await generateRAGContext(query, 'material');

  expect(ragContext.token_count).toBeLessThan(2000);
  // vs ~8000 tokens for full database
});
```

### 2. Semantic Search Accuracy
```typescript
// Verifica similitud > 60% para queries relevantes
it('should find relevant documents', async () => {
  const results = await searchKnowledge({
    query: 'aluminio 7075 aeron√°utico',
    agent_type: 'material',
  });

  expect(results[0].similarity).toBeGreaterThan(0.6);
});
```

### 3. External Service Detection
```typescript
// Cr√≠tico: Verifica que detecta servicios externos
it('should identify anodizado as external', async () => {
  const result = await checkIfServiceIsExternal({
    service_description: 'anodizado',
  });

  expect(result.is_external).toBe(true);
  expect(result.reason).toContain('NO realiza');
});
```

### 4. Tool Integration
```typescript
// Verifica workflow completo: check stock ‚Üí properties ‚Üí supplier
it('should work together', async () => {
  const stock = await checkMaterialStock({ material_code: 'AA7075' });
  const properties = await getMaterialProperties({ material_query: 'aluminio 7075' });
  const supplier = await findMaterialSupplier({ material_code: 'AA7075' });

  expect(stock).toBeDefined();
  expect(properties.source_docs.length).toBeGreaterThan(0);
  expect(supplier).toBeDefined();
});
```

---

## ‚ö° Performance Benchmarks

### Expected Performance

| Test | Expected Time | Description |
|------|--------------|-------------|
| Generate embedding | < 500ms | Single text embedding |
| RAG search | < 1000ms | Semantic search + format |
| Check material stock | < 500ms | Database query |
| Get material properties | < 1500ms | RAG search |
| Find supplier | < 1500ms | RAG search |
| Generate email | < 1000ms | Template generation |
| Agent execution | < 10s | Full agent response with RAG |
| Integration test | < 15s | Multiple operations |

### Performance Tests

```bash
# Run only performance-related tests
npx vitest --testNamePattern="Performance|fast|concurrent"
```

---

## üêõ Debugging Tests

### Verbose Output

```bash
npm test -- --reporter=verbose
```

### Debug Single Test

```bash
npx vitest --no-coverage tests/services/rag.service.test.ts --reporter=verbose
```

### Common Issues

**1. "OPENAI_API_KEY not configured"**
- Ensure `.env.local` exists
- Verify `OPENAI_API_KEY` is set

**2. "Knowledge base empty"**
- Run `npm run seed-knowledge` first
- Verify Supabase connection

**3. "Timeout exceeded"**
- Increase timeout for slow connections
- Check internet connection
- Verify OpenAI API is accessible

**4. "No results found"**
- Check knowledge base is seeded
- Verify match_threshold is not too high
- Check query is in Spanish (knowledge base is Spanish)

---

## üìà Test Metrics

### Code Coverage Targets
- Lines: > 80%
- Functions: > 80%
- Branches: > 70%

### Quality Metrics
- Similarity score: > 60% for relevant queries
- Token reduction: > 70% vs full database
- Response time: < 2s for tools, < 10s for agents
- Error rate: < 1%

---

## üîÑ Continuous Integration

### Pre-commit Checks

```bash
# Type check
npm run type-check

# Run tests
npm test

# Coverage check
npm run test:coverage
```

### CI Pipeline (example)

```yaml
test:
  steps:
    - name: Install dependencies
      run: npm ci

    - name: Type check
      run: npm run type-check

    - name: Run tests
      run: npm test

    - name: Upload coverage
      uses: codecov/codecov-action@v3
```

---

## üìù Writing New Tests

### Test Template

```typescript
import { describe, it, expect, beforeAll } from 'vitest';

describe('Your Feature', () => {
  beforeAll(() => {
    // Setup if needed
  });

  describe('Feature Functionality', () => {
    it('should do something', async () => {
      // Arrange
      const input = {...};

      // Act
      const result = await yourFunction(input);

      // Assert
      expect(result).toHaveProperty('expectedProperty');
      expect(result.value).toBe(expectedValue);
    });

    it('should handle edge cases', async () => {
      // Test edge cases
    });

    it('should handle errors gracefully', async () => {
      // Test error handling
    });
  });

  describe('Performance', () => {
    it('should be fast', async () => {
      const start = Date.now();
      await yourFunction(input);
      const duration = Date.now() - start;

      expect(duration).toBeLessThan(2000);
    });
  });
});
```

---

## ü§ù Contributing

When adding new features:

1. **Write tests first** (TDD approach)
2. **Ensure tests pass** before committing
3. **Maintain coverage** above 80%
4. **Document test scenarios** in comments
5. **Update this README** with new test info

---

## üìö Resources

- [Vitest Documentation](https://vitest.dev/)
- [Testing Best Practices](https://github.com/goldbergyoni/javascript-testing-best-practices)
- [OpenAI Testing Guide](https://platform.openai.com/docs/guides/testing)

---

**Last Updated**: 2025-10-17
**Test Coverage**: ~85%
**Total Tests**: 100+
